{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372138d1",
   "metadata": {},
   "source": [
    "# CMS Open Data $t\\bar{t}$-analysis using RDF\n",
    "This notebook was developed to showcase [RDF](https://root.cern/doc/master/classROOT_1_1RDataFrame.html)\n",
    "applying to [2015 CMS Open Data](https://cms.cern/news/first-cms-open-data-lhc-run-2-released) $t\\bar{t}$-analysis.\\\n",
    "This is a technical implementation of the analysis procedure described [here](https://github.com/andriiknu/RDF/blob/master/doc.ipynb).\\\n",
    "There is [another implementation](https://github.com/iris-hep/analysis-grand-challenge/blob/main/analyses/cms-open-data-ttbar/coffea.ipynb) producing the same results using [Coffea analysis framework]((https://github.com/iris-hep/analysis-grand-challenge/blob/main/analyses/cms-open-data-ttbar/coffea.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cbd8d",
   "metadata": {},
   "source": [
    "### Setting up environment: imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "078f248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/06\n",
      "The num of threads = 12\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ROOT\n",
    "from ROOT import RDataFrame, TCanvas, THStack\n",
    "ROOT.EnableImplicitMT()\n",
    "import numpy as np\n",
    "%jsroot on\n",
    "print(f'The num of threads = {ROOT.GetThreadPoolSize()}')\n",
    "# ROOT.TH1.SetDefaultSumw2(true)\n",
    "# verbosity = ROOT.Experimental.RLogScopedVerbosity(ROOT.Detail.RDF.RDFLogChannel(), ROOT.Experimental.ELogLevel.kInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83dc22",
   "metadata": {},
   "source": [
    "### Setting up environment: ***helper.cpp*** compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb7943c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT.gSystem.CompileMacro(\"helper.cpp\", \"kO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48e11a",
   "metadata": {},
   "source": [
    "`helper.cpp` is a file containing helpful c++ functions to perform analysis.\\\n",
    "A couple of them gives scaling factors applied for variations construction:\n",
    "* *`pt_scale_up`*: jet transverse momentum values scaling by a constant factor\n",
    "* *`pt_res_up`*: jet transverse momentum values scaling according to normal distribution\n",
    "* *`btag_weight_variation`*: weights variations\n",
    "* *`flat_variation`*: weights flat variations some of the processes\n",
    "\n",
    "Other of them are written for ROOT histogram slicing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c081322",
   "metadata": {},
   "source": [
    "### Global configurations\n",
    " `N_FILES_MAX_PER_SAMPLE`  is a variable determining the number of input files per sample, i. e. the dataset size to be processed.\\\n",
    "9 samples are being used here, all part of the 2015 CMS Open Data release. \n",
    "More details about the inputs can be found [here](https://github.com/iris-hep/analysis-grand-challenge/tree/main/datasets/cms-open-data-2015) or in the [Coffea implementation](https://github.com/iris-hep/analysis-grand-challenge/blob/main/analyses/cms-open-data-ttbar/coffea.ipynb) mentioned at the beginning.\n",
    "\n",
    "`LOCAL` specify whether input files are locally placed. To use it, you must save input files locally by setting `DOWNLOAD` to `True`. This option will create an `input` directory to save input files. Otherwise, turn off the `LOCAL` and `DOWNLOAD` options by setting `False` to both. If `LOCAL` equals `False`, remote inputs will be accessed through HTTPS. \n",
    "\n",
    "`FILE` is the name of the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9affd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILES_MAX_PER_SAMPLE = 1\n",
    "DOWNLOAD = False\n",
    "LOCAL = False\n",
    "FILE = f'rdf-{N_FILES_MAX_PER_SAMPLE}.root'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aefc97",
   "metadata": {},
   "source": [
    "### TtbarAnalysis class definition\n",
    "Encapsulates full analysis pipeline and provides helpful methods for data delivery and processing, and histogram construction. Serves as analysis manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df32dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "\n",
    "\n",
    "class TtbarAnalysis(dict):\n",
    "\n",
    "    def __init__(self, n_files_max_per_sample = 1, num_bins=25, bin_low = 50, bin_high = 550, download_input_data=False, use_local_data=False):\n",
    "        \n",
    "        \n",
    "        self.variations = {} # serves as temporary storage for all histograms produced by VariationsFor\n",
    "        self.download_input_data = download_input_data  # set True to download input files\n",
    "        self.use_local_data = use_local_data            # set True to use locally placed input files instead of https accessing\n",
    "        self._nevts_total = {}\n",
    "        self.n_files_max_per_sample = n_files_max_per_sample  #the number of files to be processed per sample\n",
    "        self.input_data = self._construct_fileset() # dictionary assigning file URLs (paths) to each process, variation, and region\n",
    "        self.num_bins = num_bins\n",
    "        self.bin_low = bin_low\n",
    "        self.bin_high = bin_high\n",
    "        # using https://atlas-groupdata.web.cern.ch/atlas-groupdata/dev/AnalysisTop/TopDataPreparation/XSection-MC15-13TeV.data\n",
    "        # for reference\n",
    "        # x-secs are in pb\n",
    "        self.xsec_info = {\n",
    "            \"ttbar\": 396.87 + 332.97, # nonallhad + allhad, keep same x-sec for all\n",
    "            \"single_top_s_chan\": 2.0268 + 1.2676,\n",
    "            \"single_top_t_chan\": (36.993 + 22.175)/0.252,  # scale from lepton filter to inclusive\n",
    "            \"single_top_tW\": 37.936 + 37.906,\n",
    "            \"wjets\": 61457 * 0.252,  # e/mu+nu final states\n",
    "            \"data\": None\n",
    "        }\n",
    "        ROOT.gInterpreter.Declare(f\"auto pt_res_up_obj = pt_res_up({ROOT.GetThreadPoolSize()});\")\n",
    "        \n",
    "\n",
    "    def _construct_fileset(self):\n",
    "        n_files_max_per_sample = self.n_files_max_per_sample\n",
    "        with open ('ntuples.json') as f:\n",
    "            file_info = json.load(f)\n",
    "        fileset = {}\n",
    "        for process in file_info.keys():\n",
    "            if process == \"data\":\n",
    "                continue  # skip data\n",
    "            fileset[process] = {}\n",
    "            self[process] = {}\n",
    "            self._nevts_total[process] = {}\n",
    "            for variation in file_info[process].keys():\n",
    "#                 if variation != 'nominal': continue      \n",
    "                file_list = file_info[process][variation][\"files\"]\n",
    "                if n_files_max_per_sample != -1:\n",
    "                    file_list = file_list[:n_files_max_per_sample]  # use partial set of samples\n",
    "                file_paths = [f[\"path\"] for f in file_list]\n",
    "                nevts_total = sum([f[\"nevts\"] for f in file_list])\n",
    "                self._nevts_total[process].update({variation:nevts_total})\n",
    "                fileset[process].update({variation: file_paths})\n",
    "                #download input files if turned\n",
    "                if (self.download_input_data):\n",
    "                    dir_name = f\"input/{process}_{variation}\"\n",
    "                    os.makedirs(dir_name, exist_ok=True)\n",
    "                    for i in range(len(file_paths)):\n",
    "                        path = file_paths[i]\n",
    "                        file = f\"{dir_name}/{i}.root\"\n",
    "                        if not os.path.exists(file):\n",
    "                            urlretrieve(path, file)   \n",
    "                            print(f\"{file} has been created\")\n",
    "                        else:\n",
    "                            print(f\"{file} already exists\")\n",
    "                self[process][variation] = {}\n",
    "                \n",
    "        return fileset\n",
    "\n",
    "    def fill(self, process, variation, ):\n",
    "        \n",
    "        # analysis algorithm themself implemented here\n",
    "        # fill function accepts parameters pair (process, variation) to which are assigned files in self.input_data\n",
    "        \n",
    "        # all operations are handled by RDataFrame class, so the first step is the RDataFrame object instantiating\n",
    "        input_data = [f\"root://eosuser.cern.ch//eos/user/a/afalko/analysis-grand-challenge/analyses/cms-open-data-ttbar/input/{process}_{variation}/{i}.root\" for i in range(self.n_files_max_per_sample)] if self.use_local_data else self.input_data[process][variation]               \n",
    "        d = RDataFrame('events', input_data)\n",
    "        \n",
    "        # normalization for MC\n",
    "        x_sec = self.xsec_info[process]\n",
    "        nevts_total = self._nevts_total[process][variation]\n",
    "        lumi = 3378 # /pb\n",
    "        xsec_weight = x_sec * lumi / nevts_total\n",
    "        d = d.Define('weights', str(xsec_weight)) #default weights\n",
    "        \n",
    "        \n",
    "        \n",
    "        if variation == 'nominal':\n",
    "            \n",
    "            # jet_pt variations definition\n",
    "            # pt_scale_up() and pt_res_up(jet_pt) return scaling factors applying to jet_pt\n",
    "            # pt_scale_up() - jet energy scaly systematic\n",
    "            # pt_res_up(jet_pt) - jet resolution systematic \n",
    "\n",
    "            \n",
    "            d = d.Vary('jet_pt', \"ROOT::RVec<ROOT::RVecF>{jet_pt*pt_scale_up(), jet_pt*pt_res_up_obj(jet_pt, rdfslot_)}\", [\"pt_scale_up\", \"pt_res_up\"])\n",
    "            if process == 'wjets':\n",
    "                \n",
    "                # flat weight variation definition\n",
    "                d = d.Vary('weights', \n",
    "                           \"weights*flat_variation()\",\n",
    "                           [f\"scale_var_{direction}\" for direction in [\"up\", \"down\"]]\n",
    "                          )\n",
    "                \n",
    "        ### event selection - the core part of the algorithm applied for both regions\n",
    "        # selecting events containing at least one lepton and four jets with pT > 25 GeV\n",
    "        # applying requirement at least one of them must be b-tagged jet (see details in the specification)\n",
    "        d = d.Define('electron_pt_mask', 'electron_pt>25').Define('muon_pt_mask', 'muon_pt>25').Define('jet_pt_mask', 'jet_pt>25')\\\n",
    "             .Filter('Sum(electron_pt_mask) + Sum(muon_pt_mask) == 1')\\\n",
    "             .Filter('Sum(jet_pt_mask) >= 4')\\\n",
    "             .Filter('Sum(jet_btag[jet_pt_mask]>=0.5)>=1')\n",
    "             \n",
    "        \n",
    "        # b-tagging variations for nominal samples\n",
    "        d = d.Vary('weights', \n",
    "                   'ROOT::RVecD{weights*btag_weight_variation(jet_pt[jet_pt_mask])}',\n",
    "                   [f\"{weight_name}_{direction}\" for weight_name in [f\"btag_var_{i}\" for i in range(4)] for direction in [\"up\", \"down\"]]\n",
    "                  ) if variation == 'nominal' else d\n",
    "        \n",
    "        \n",
    "\n",
    "        ## as next steps for different regions are different, there is a fork in the algorithm\n",
    "        # we create another RDF pointer for each region called \"fork\"\n",
    "        measured = {\"4j1b\": \"HT\", \"4j2b\": 'trijet_mass'} # columns names of observables for two regions\n",
    "        for region in [\"4j1b\",\"4j2b\"]:\n",
    "            observable = measured[region]\n",
    "            \n",
    "            if region == \"4j1b\":\n",
    "                \n",
    "                # only one b-tagged region required\n",
    "                # observable is total transvesre momentum \n",
    "                fork = d.Filter('Sum(jet_btag[jet_pt_mask]>=0.5)==1').Define(observable, 'Sum(jet_pt[jet_pt_mask])')      \n",
    "\n",
    "            elif region == \"4j2b\":\n",
    "                \n",
    "                # select events with at least 2 b-tagged jets\n",
    "                # building four-momentum vectors for each jet\n",
    "                fork = d.Filter('Sum(jet_btag[jet_pt_mask]>=0.5)>1').Define(\"jet_p4\", \n",
    "                    \"ROOT::VecOps::Construct<ROOT::Math::PxPyPzMVector>(jet_px[jet_pt_mask], jet_py[jet_pt_mask], jet_pz[jet_pt_mask], jet_mass[jet_pt_mask])\"\n",
    "                )\n",
    "                \n",
    "                # building trijet combinations\n",
    "                fork = fork.Define('trijet', \n",
    "                    'ROOT::VecOps::Combinations(jet_pt[jet_pt_mask],3)'\n",
    "                ).Define('ntrijet', 'trijet[0].size()')\n",
    "\n",
    "                # assigning four-momentums to each trijet combination\n",
    "                fork = fork.Define('trijet_p4', \n",
    "                                      'ROOT::VecOps::RVec<ROOT::Math::PxPyPzMVector> trijet_p4(ntrijet);'              +\\\n",
    "                                      'for (int i = 0; i < ntrijet; ++i) {'                                            +\\\n",
    "                                          'int j1 = trijet[0][i]; int j2 = trijet[1][i]; int j3 = trijet[2][i];'       +\\\n",
    "                                          'trijet_p4[i] = jet_p4[j1] + jet_p4[j2] + jet_p4[j3];'                       +\\\n",
    "                                      '}'                                                                              +\\\n",
    "                                      'return trijet_p4;'                                                                                                                          \n",
    "                                     )\n",
    "\n",
    "                # getting trijet transverse momentum values from four-momentum vectors\n",
    "                fork = fork.Define('trijet_pt', \n",
    "                        'return ROOT::VecOps::Map(trijet_p4, [](ROOT::Math::PxPyPzMVector v) { return v.Pt(); })'\n",
    "                                            )\n",
    "\n",
    "              \n",
    "                # trijet_btag is a helpful array of bool values indicating whether or not the maximum btag value in trijet is larger than 0.5 threshold \n",
    "                fork = fork.Define('trijet_btag', \n",
    "                                                  'ROOT::VecOps::RVec<bool> btag(ntrijet);'                                   +\\\n",
    "                                                  'for (int i = 0; i < ntrijet; ++i) {'                                       +\\\n",
    "                                                   'int j1 = trijet[0][i]; int j2 = trijet[1][i]; int j3 = trijet[2][i];'     +\\\n",
    "                                                   'btag[i]=std::max({jet_btag[j1], jet_btag[j2], jet_btag[j3]})>0.5;'        +\\\n",
    "                                                  '}'                                                                         +\\\n",
    "                                                  'return btag;'\n",
    "                                            )\n",
    "                # find trijet with maximum pt and higher that threshold btag\n",
    "                # get mass for found jet four-vector \n",
    "                # trijet mass themself is an observable quantity\n",
    "                fork=fork.Define(observable,\n",
    "                                                  'double mass;'+\\\n",
    "                                                  'double Pt = 0;'+\\\n",
    "                                                  'double indx = 0;'+\\\n",
    "                                                  'for (int i = 0; i < ntrijet; ++i) {'               +\\\n",
    "                                                  '    if ((Pt < trijet_pt[i]) && (trijet_btag[i])) {'+\\\n",
    "                                                  '        Pt = trijet_pt[i];'+\\\n",
    "                                                  '        indx=i;'+\\\n",
    "                                                  '    }'                                            +\\\n",
    "                                                  '}'                                                +\\\n",
    "                                                  'mass = trijet_p4[indx].M();'             +\\\n",
    "                                                  'return mass;'\n",
    "                                                 )\n",
    "                \n",
    "            \n",
    "            # fill histogram for observable column in RDF object\n",
    "            \n",
    "            res = fork.Histo1D((f'{process}_{variation}_{region}', process, self.num_bins, self.bin_low, self.bin_high), observable, 'weights')\n",
    "            self.hist.append(res) # save the pointer to further triggering \n",
    "            print(f'histogram {region}_{process}_{variation} has been created')\n",
    "            \n",
    "            # save pointers for variations\n",
    "            # self.variations is a temporary container for all pointers\n",
    "            if variation == 'nominal':\n",
    "                self.variations[f\"{process}__{region}\"] = ROOT.RDF.Experimental.VariationsFor(res)\n",
    "            else:\n",
    "                self[process][variation][region] = res\n",
    "\n",
    "    # build 9 Graphs for each data sample            \n",
    "    def Fill(self):\n",
    "        self.hist = []\n",
    "        for process in self:\n",
    "            \n",
    "            for variation in self.input_data[process]:\n",
    "                self.fill(process=process, variation=variation)\n",
    "\n",
    "    # run 9 Graphs for each data sample            \n",
    "    def Accumulate(self):\n",
    "        ROOT.RDF.RunGraphs(self.hist)  \n",
    "    \n",
    "    # transform TtbarAnalysis to dictionary (process, variation, region) -> hitogram\n",
    "    def TransfToDict(self):\n",
    "        for key in self.variations.keys():\n",
    "            hist_map = self.variations[key]\n",
    "            key = str(key).split('__')\n",
    "            process = key[0]; region = key[1]\n",
    "            for hist_name in hist_map.GetKeys():\n",
    "                variation = 'nominal' if hist_name == 'nominal' else str(hist_name).split(':')[1]\n",
    "                if variation not in self[process]: self[process][variation] = {}\n",
    "                hist = hist_map[hist_name]\n",
    "                if not isinstance(hist, ROOT.TH1D): hist = hist.GetValue()\n",
    "                analysisManager[process][variation][region] = hist\n",
    "        analysisManager.ExportJSON()\n",
    "        \n",
    "    def GetProcStack(self, region, variation='nominal'):\n",
    "        return [self[process][variation][region] for process in self]\n",
    "    \n",
    "    def GetVarStack(self, region, key, process=\"ttbar\"):\n",
    "        variations = []\n",
    "        for variation in self[process]:\n",
    "            if key in variation or variation=='nominal': variations.append(variation)\n",
    "        res = []\n",
    "        for variation in variations:\n",
    "            self[process][variation][region].SetTitle(variation)\n",
    "            res.append(self[process][variation][region])\n",
    "        return res\n",
    "        \n",
    "    \n",
    "    # necessary only for sanity checks\n",
    "    def ExportJSON(self):\n",
    "        data = {}\n",
    "        for process in self:\n",
    "            data[process] = {}\n",
    "            for variation in self[process]:\n",
    "                data[process][variation] = [region for region in self[process][variation]]\n",
    "        with open('data.json', 'w') as f:\n",
    "            json.dump(data, f)\n",
    "                \n",
    "                \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b78353",
   "metadata": {},
   "source": [
    "### Analysis manager configuration\n",
    "To perform analysis, one needs to instantiate the TtbarAnalysis object. TtbarAnalysis constructor method accepts arguments determining all TtbarAnalysi analysis behavior.\n",
    "Main settings:\n",
    "* `n_files_max_per_sample` - the number of files which will be processed per sample (1 by default)\n",
    "* `use_local_data` - choose locally or remotely placed input files\n",
    "* `download_input_data` - specify will or not the files be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1303a442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysisManager = TtbarAnalysis(download_input_data=DOWNLOAD, use_local_data=LOCAL, n_files_max_per_sample = N_FILES_MAX_PER_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f8bf1",
   "metadata": {},
   "source": [
    "At this stage, analysisManager keeps all file URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0425be82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processes in fileset: ['ttbar', 'single_top_s_chan', 'single_top_t_chan', 'single_top_tW', 'wjets']\n",
      "\n",
      "example of information inside analysisManager:\n",
      "{\n",
      "  'urls': [https://xrootd-local.unl.edu:1094//store/user/AGC/datasets/RunIIFall15MiniAODv2/TT_TuneCUETP8M1_13TeV-powheg-pythia8/MINIAODSIM//PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1/00000/00DF0A73-17C2-E511-B086-E41D2D08DE30.root, ...],\n"
     ]
    }
   ],
   "source": [
    "print(f\"processes in fileset: {list(analysisManager.keys())}\")\n",
    "print(f\"\\nexample of information inside analysisManager:\\n{{\\n  'urls': [{analysisManager.input_data['ttbar']['nominal'][0]}, ...],\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2a3ef",
   "metadata": {},
   "source": [
    "Note, if you set **`use_local_data`** to the **`True`**, **local paths** will be used instead of printed URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592024fc",
   "metadata": {},
   "source": [
    "### Build histograms and execute data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70a550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histogram 4j1b_ttbar_nominal has been created\n",
      "histogram 4j2b_ttbar_nominal has been created\n",
      "histogram 4j1b_ttbar_scaledown has been created\n",
      "histogram 4j2b_ttbar_scaledown has been created\n",
      "histogram 4j1b_ttbar_scaleup has been created\n",
      "histogram 4j2b_ttbar_scaleup has been created\n",
      "histogram 4j1b_ttbar_ME_var has been created\n",
      "histogram 4j2b_ttbar_ME_var has been created\n",
      "histogram 4j1b_ttbar_PS_var has been created\n",
      "histogram 4j2b_ttbar_PS_var has been created\n",
      "histogram 4j1b_single_top_s_chan_nominal has been created\n",
      "histogram 4j2b_single_top_s_chan_nominal has been created\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "analysisManager.Fill()\n",
    "t1 = time.time()\n",
    "print(f\"\\npreprocessing took {round(t1 - t0,2)} seconds\")\n",
    "analysisManager.Accumulate()\n",
    "t2 = time.time()\n",
    "print(f\"processing took {round(t2 - t1,2)} seconds\")\n",
    "print(f\"execution took {round(t2 - t0,2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysisManager.TransfToDict()\n",
    "analysisManager['ttbar'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d26c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%jsroot off\n",
    "c = TCanvas('c', 'c', 3000*2, 2000*2) \n",
    "hlist = analysisManager.GetProcStack(region='4j1b')\n",
    "hs = THStack('j4b1', '>=4 jets, 1 b-tag; H_{T} [GeV]')\n",
    "for h in hlist:\n",
    "    ptr = ROOT.Slice(h, 120, 550)\n",
    "    ptr = ptr.Rebin(2, ptr.GetTitle())\n",
    "    hs.Add(ptr)\n",
    "hs.Draw('hist pfc plc')\n",
    "c.Draw()\n",
    "x = hs.GetXaxis()\n",
    "x.SetTitleOffset(1.5)\n",
    "x.CenterTitle()\n",
    "c.BuildLegend(0.65, 0.7, 0.9, 0.9)\n",
    "c.SaveAs('plots/reg1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34105b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hlist = analysisManager.GetProcStack(region='4j2b')\n",
    "hs = THStack('j4b1', '>=4 jets, 2 b-tag; m_{bjj} [Gev]')\n",
    "for h in hlist:\n",
    "    hs.Add(h)\n",
    "hs.Draw('hist pfc plc')\n",
    "c.Draw()\n",
    "x = hs.GetXaxis()\n",
    "x.SetTitleOffset(1.5)\n",
    "x.CenterTitle()\n",
    "c.BuildLegend(0.65, 0.7, 0.9, 0.9)\n",
    "c.SaveAs('plots/reg2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ae6b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freshstack = analysisManager.GetVarStack(region='4j1b', key='btag')\n",
    "hs = THStack('j4b1btag', \"b-tagging variations; H_{T} [GeV]\")\n",
    "for h in freshstack:\n",
    "    ptr = h.Rebin(2, h.GetTitle())\n",
    "    ptr.SetFillColor(0)\n",
    "    ptr.SetLineWidth(5)\n",
    "    hs.Add(ptr)\n",
    "hs.Draw('hist nostack plc')\n",
    "c.Draw()\n",
    "x = hs.GetXaxis()\n",
    "x.SetRangeUser(120, 500)\n",
    "x.SetTitleOffset(1.5)\n",
    "x.CenterTitle()\n",
    "c.BuildLegend(0.65, 0.6, 0.9, 1.0)\n",
    "c.SaveAs('plots/btag.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb39c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freshstack = analysisManager.GetVarStack(region='4j2b', key='pt')\n",
    "hs = THStack('j4b1btag', \"Jet energy variations; m_{bjj} [Gev]\")\n",
    "for h in freshstack:\n",
    "    ptr.SetFillColor(0)\n",
    "    ptr.SetLineWidth(5)\n",
    "    hs.Add(ptr)\n",
    "hs.Draw('hist nostack plc')\n",
    "c.Draw()\n",
    "x = hs.GetXaxis()\n",
    "x.SetTitleOffset(1.5)\n",
    "x.CenterTitle()\n",
    "c.BuildLegend(0.7, 0.75, 0.9, 0.9)\n",
    "c.SaveAs('plots/pt_var.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cabeed6",
   "metadata": {},
   "source": [
    "### Save histograms to disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858b090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_scaledown (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_scaleup (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_ME_var (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_PS_var (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n",
      "Warning in <TFile::Append>: Replacing existing TH1: h_sliced_nominal (Potential memory leak).\n"
     ]
    }
   ],
   "source": [
    "output = ROOT.TFile.Open(FILE, 'RECREATE')\n",
    "for process in analysisManager:\n",
    "    for variation in analysisManager[process]:\n",
    "        for region in analysisManager[process][variation]:\n",
    "            hist_name = f\"{region}_{process}_{variation}\" if variation != 'nominal' else f\"{region}_{process}\"\n",
    "            hist = analysisManager[process][variation][region]\n",
    "            if not isinstance(hist, ROOT.TH1D): hist = hist.GetValue() #this this a bag\n",
    "            if hist.IsZombie(): raise TypeError(hist_name)\n",
    "            hist_sliced = ROOT.Slice(hist, 120, 550)\n",
    "            hist_binned = hist_sliced.Rebin(2, hist.GetTitle())\n",
    "            output.WriteObject(hist_binned, hist_name)\n",
    "output.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c393da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
