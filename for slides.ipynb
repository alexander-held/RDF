{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73aa956e",
   "metadata": {},
   "source": [
    "## 2 Slide\n",
    "Let's start with a bit of context. Here is what is ttbar analysis. So, you know top-quarks are produced in proton-proton collisions at LHC. And the first analysis task is the define the basic algorithm for distinguishing the t-quark pair production channel among other concurrent channels some of which are presented in the left part of this slide. \n",
    "But how can one be sure he selected the same events as he needs. The efficiency of an algorithm can be shown using simulated data in which one can exactly know whether or not the t-quark pair is produced in any particular event.  \n",
    "The algorithm that I speak about already has been implemented by my mentor Alex and on the right side of this slide is presented the example of some of the produced histograms in his implementation. That is the top-quark mass plot. You can see that it is not ideal because there are contributions from other processes in this stack, but they are very small and this algorithm in principle can be improved. \n",
    "So, my task is the provide another implementation of ttbar analysis using ROOT's modern analysis facility RDF. And this project actually aims to get the same results using RDF that was gotten in Coffea to compare both workflows and provide the community a good example of using RDF upon real data. \n",
    "\n",
    "## 3 Slide\n",
    "Let's go into some details about ttbar-analysis. So, the ttbar-analysis algorithm relies on the semileptonic decay schema, presented on the slide. We can identify events with t-quarks pair annihilation by observing decay products. As can be concluded from this diagram, one lepton, two jets, and two b-jets are expected to be detected in the semi-leptonic ttbar decay channel. \n",
    "So the first part of the algorithm is selecting events containing all mentioned particles. \n",
    "The mass of the top-quark can be restored by two b-jet and one jet, so the second part of the algorithm is defining the trijet combination which is assumed to be the decay product of the t-quark per every event.\n",
    "This is the image from my chapter summarizing the full analysis pipeline.\n",
    "\n",
    "## 4 Slide\n",
    "So, what I have achieved so far? Firstly, I have wrought a detailed ttbar analysis description in plain English, and, secondly produce the same histograms using RDF, as Alex in Coffea. \n",
    "\n",
    "## 5 Slide\n",
    "But what do I have to do else? I need to implement one more algorithm to produce one more histogram stack and include in my implementation different kinds of systematic uncertainties and after all test my program upon Large data sets in the CERN cluster.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429db6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
